{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openeo\n",
    "import geopandas as gpd\n",
    "import os\n",
    "import rasterio\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to use GeoPandas and OpenEo\n",
    "\n",
    "This notebook shows some of the functions, libraries and file formats we use in the chapter, in case you're not familiar with them.\n",
    "\n",
    "GeoPandas is a library to work with tables holding geographic information. This geographic information is represented by sets of coordinates, which can define points, lines or polygons (or multi-polygons).\n",
    "\n",
    "Geopackage is a file type (`.gpkg`) that can hold layers of geographical information. In our case, the notebook in `/data_preparation` created a `.gpkg` with polygon/multipolygon geometries (Paris' parks) and a layer f points (Paris's Parks centroids).\n",
    "\n",
    "We can explore the `.gpkg` file with GeoPandas and the `list_layers` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geopackage_path = \"../src/data/paris_parks.gpkg\"\n",
    "\n",
    "layer_names = gpd.list_layers(geopackage_path)\n",
    "\n",
    "print(layer_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can uise each layer to create a GeoPandas GeoDataFrame. GepDataFrames have tabular data (just like a pandas DataFrame), but also geographic information. Each column in the GeoDataFrame is an **attribute** of the geographical object (for example, `postal_code` is an attribute of Paris' parks):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_paris_parks = gpd.read_file(geopackage_path, layer=\"parks_polygons\")\n",
    "gdf_park_centroid = gpd.read_file(geopackage_path, layer=\"parks_centroids\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_paris_parks.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like pandas, GeoPandas has a `.plot()` method, it \"knows\" what to plot. `gdf_paris_parks` has polygons, and `gdf_park_centroid` has points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_paris_parks.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_park_centroid.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ploting with Plotly\n",
    "\n",
    "We can plot GeoDataFrames with Plotly.\n",
    "Since we have centroids for each polygon, we can use them to center the map around them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_park_with_centroid(\n",
    "    gdf_parks, gdf_park_centroid, park_id, map_style=\"open-street-map\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Plots a specific park with its centroid on a Plotly map.\n",
    "\n",
    "    Args:\n",
    "        gdf_parks (geopandas.GeoDataFrame): GeoDataFrame containing park polygons.\n",
    "        gdf_park_centroid (geopandas.GeoDataFrame): GeoDataFrame containing park centroids.\n",
    "        park_id (str or int): The ID of the park to plot.\n",
    "        map_style (str, optional): Mapbox style. Defaults to \"open-street-map\".\n",
    "\n",
    "    Returns:\n",
    "        plotly.graph_objects.Figure: A Plotly map figure, or None if the park is not found.\n",
    "    \"\"\"\n",
    "\n",
    "    park_polygon = gdf_parks[gdf_parks[\"id\"] == park_id].copy()\n",
    "    park_centroid = gdf_park_centroid[gdf_park_centroid[\"id\"] == park_id].copy()\n",
    "\n",
    "    if park_polygon.empty or park_centroid.empty:\n",
    "        return None\n",
    "\n",
    "    # Get centroid coordinates\n",
    "    centroid_point = park_centroid[\"geometry\"].iloc[0]\n",
    "    center = {\"lat\": centroid_point.y, \"lon\": centroid_point.x}\n",
    "\n",
    "    fig = px.choropleth_mapbox(\n",
    "        park_polygon,\n",
    "        geojson=park_polygon.geometry.__geo_interface__,\n",
    "        locations=park_polygon.index,\n",
    "        center=center,\n",
    "        mapbox_style=map_style,\n",
    "        zoom=15,\n",
    "        opacity=0.5,\n",
    "        hover_name=\"name\",\n",
    "        hover_data={\n",
    "            \"name\": True,\n",
    "            \"type\": True,\n",
    "            \"category\": True,\n",
    "            \"area_sqm\": True,\n",
    "        },\n",
    "    )\n",
    "\n",
    "    fig.update_layout(margin={\"r\": 0, \"t\": 0, \"l\": 0, \"b\": 0})\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_park_with_centroid(\n",
    "    gdf_parks=gdf_paris_parks,\n",
    "    gdf_park_centroid=gdf_park_centroid,\n",
    "    park_id=2425,\n",
    "    map_style=\"open-street-map\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting to DataFrame\n",
    "\n",
    "In case you need it, you can convert a GeoDataFrame into a DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_paris_parks = pd.DataFrame(gdf_paris_parks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_paris_parks.groupby(\"type\").size().reset_index(name=\"count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenEO\n",
    "\n",
    "[OpenEO](https://pypi.org/project/openeo/) (\"EO\" for Earth Observation) is a Python library that provides an API to interact with backends that serve geographic information.\n",
    "\n",
    "For our app, we'll be using Sentinel-2 data, from the European Space Agency (ESA).\n",
    "\n",
    "**You need to create an account: https://dataspace.copernicus.eu/**.\n",
    "\n",
    "![](../img/account.png)\n",
    "\n",
    "**You'll also need to create credentials**:\n",
    "\n",
    "* Go to your account's settings (likely: https://shapps.dataspace.copernicus.eu/dashboard/#/account/settings)\n",
    "\n",
    "\n",
    "### Important resources:\n",
    "\n",
    "* [OpenEO's documentation about datacubes, the most important concept to understand the app's algorithms](https://openeo.org/documentation/1.0/datacubes.html#what-are-datacubes]).\n",
    "\n",
    "* [Notebooks to chek out]( https://dataspace.copernicus.eu/cases).\n",
    "\n",
    "## Defining functions\n",
    "\n",
    "These are the functions we use in the pipelines, for pour Scenario and also for our Generic Data Nodes.\n",
    "\n",
    "The first one retrieves a Polygon from our previou GeoDataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_polygon(gdf_paris_parks, id):\n",
    "    polygon = gdf_paris_parks[gdf_paris_parks[\"id\"] == id].geometry.__geo_interface__\n",
    "    return polygon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPORTANT:** This function returns the connector to our Copernicus's space. You'll need to provide your credentials.\n",
    "\n",
    "**We highly recommend using environment variables to store your credentials!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_to_copernicus(\n",
    "    client_id, client_secret, url=\"https://openeo.dataspace.copernicus.eu\"\n",
    "):\n",
    "    connection = openeo.connect(url)\n",
    "    connection.authenticate_oidc_client_credentials(\n",
    "        client_id=client_id, client_secret=client_secret\n",
    "    )\n",
    "    return connection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **datacube** holds the following dimensions:\n",
    "\n",
    "* **Time**: we need to provide the time extent for the Earth's Observations. Sentinel 2 goes over each spot on Earth every 3 days more or less. Each observation is one picture from the satellite.\n",
    "* **Spatial Extent**: The surface of the observed area. Bigger surfaces give more pixels.\n",
    "* **Spectral resolution:** These are the \"bands\" that record specific waves. For example, Band 04 has Near Infra Red information, and Band 08 has red information.\n",
    "\n",
    "In our case, **we'll use the app's UI to select a specific year for time obeservation, and a specific Paris' park (a polygon) for spatial extent**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_datacube(polygon, start, end, connection):\n",
    "    datacube = connection.load_collection(\n",
    "        \"SENTINEL2_L2A\",\n",
    "        temporal_extent=[start, end],\n",
    "        spatial_extent=polygon,\n",
    "        bands=[\"B04\", \"B08\", \"SCL\"],  # Red and NIR for NDVI and SCL for clouds\n",
    "    )\n",
    "    return datacube"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "source": [
    "The SCL band can be used to mask cloud data. When satellites take images of the Earth, sometimes... there are clouds. Cloud pixels alter the observation results, so we can mask them (we remove them from the observation, from the cube)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_clouds(datacube):\n",
    "    \"\"\"\n",
    "    Applies a cloud mask to a given data cube by filtering out cloud-covered pixels.\n",
    "\n",
    "    Args:\n",
    "    datacube (openeo.DataCube): The data cube containing Sentinel-2 bands.\n",
    "\n",
    "    Returns:\n",
    "    openeo.DataCube: The masked data cube with clouds removed.\n",
    "    \"\"\"\n",
    "    scl = datacube.band(\"SCL\")\n",
    "    cloud_mask = (scl == 8) | (scl == 9)  # Cloud classes\n",
    "    datacube = datacube.mask(cloud_mask)\n",
    "    return datacube"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can create datacube from another datacube**. The `ndvi` object we creeate in this function uses the bands 8 and 4 from the `datacube` object we pass as argument. It returns a datacube with a single computed band. However, we have the same spatial and time dimmensions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ndvi(datacube):\n",
    "    \"\"\"\n",
    "    Calculates Normalized Difference Vegetation Index (NDVI) from a given data cube.\n",
    "\n",
    "    Args:\n",
    "        datacube (openeo.DataCube): The data cube containing Red (B04)\n",
    "            and Near Infra-Red (NIR - B08) bands.\n",
    "\n",
    "    Returns:\n",
    "        openeo.DataCube: The computed NDVI data cube\n",
    "    \"\"\"\n",
    "    ndvi = (datacube.band(\"B08\") - datacube.band(\"B04\")) / (\n",
    "        datacube.band(\"B08\") + datacube.band(\"B04\")\n",
    "    )\n",
    "    return ndvi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following funtion groups previous steps to return a `ndvi` datacube object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ndvi(polygon, year):\n",
    "    \"\"\"\n",
    "    Retrieves and processes NDVI data for a given polygon and year.\n",
    "\n",
    "    Args:\n",
    "        polygon (dict): The spatial extent of interest in geo-interface format\n",
    "        year (int or str): The year of interest for NDVI calculation\n",
    "\n",
    "    Returns:\n",
    "        openeo.DataCube: Processed NDVI data cube with cloud masking applied\n",
    "    \"\"\"\n",
    "    connection = connect_to_copernicus(\n",
    "        client_id=os.getenv(\"COPERNICUS_ID\"),\n",
    "        client_secret=os.getenv(\"COPERNICUS_SECRET\"),\n",
    "    )\n",
    "\n",
    "    datacube = create_datacube(polygon, f\"{year}-01-01\", f\"{year}-12-31\", connection)\n",
    "    datacube = mask_clouds(datacube)\n",
    "\n",
    "    ndvi = create_ndvi(datacube)\n",
    "\n",
    "    return ndvi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reducing by time and aggregating by space are well explained in Open'EO's documentation**.\n",
    "\n",
    "\n",
    "In time reductions, for each pixel, we \"summarize\" the NDVI value for all the observation period, in this case we use the median, we could also use maximum values, the mean, or other aggregates. This gives us a 2-D array that represents the median values for the selected period, for each pixel. \n",
    "\n",
    "In spatial aggregation, we get the median NDVI value for all the pixels of each image (each 2D array) of the cube. This gives us a time series, with all the individual median values for each observation date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_by_time(ndvi):\n",
    "    \"\"\"\n",
    "    Reduces the temporal dimension of an NDVI data cube by computing the median value.\n",
    "\n",
    "    Args:\n",
    "        ndvi (openeo.DataCube): The NDVI data cube with a temporal dimension\n",
    "\n",
    "    Returns:\n",
    "        openeo.DataCube: The time-reduced data cube with median values\n",
    "    \"\"\"\n",
    "    ndvi_time_reduced = ndvi.reduce_dimension(dimension=\"t\", reducer=\"median\")\n",
    "    return ndvi_time_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time_series(ndvi, polygon):\n",
    "    \"\"\"\n",
    "    Computes a median NDVI time series for the specified polygon geometry.\n",
    "\n",
    "    Args:\n",
    "        ndvi (openeo.DataCube): The NDVI data cube with temporal dimension\n",
    "        polygon (dict): GeoJSON-like polygon geometry for spatial aggregation\n",
    "\n",
    "    Returns:\n",
    "        openeo.DataCube: Time series data cube with median NDVI values\n",
    "    \"\"\"\n",
    "    timeseries = ndvi.aggregate_spatial(geometries=polygon, reducer=\"median\")\n",
    "    return timeseries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utility functions:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_ndvi(ndvi, park_name, year):\n",
    "    \"\"\"\n",
    "    Downloads an NDVI data cube as a TIFF file, using the dictionary key as the filename.\n",
    "\n",
    "    Args:\n",
    "        ndvi: NDVI data cube to be downloaded (xarray DataArray or similar)\n",
    "        park_name (str): Name of the park/location to include in filename\n",
    "        year (int/str): Year of the data to include in filename\n",
    "\n",
    "    Returns:\n",
    "        int: Always returns 0, indicating successful completion\n",
    "    \"\"\"\n",
    "\n",
    "    ndvi.download(f\"{park_name} - {year}.tif\")\n",
    "\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_time_series(ndvi_timeseries, park_name, year):\n",
    "    title = f\"{park_name} - {year}\"\n",
    "    job = ndvi_timeseries.execute_batch(out_format=\"CSV\", title=title)\n",
    "    job.get_results().download_file(f\"{title}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_time_series(park_name, year):\n",
    "    time_series_name = f\"{park_name} - {year}.csv\"\n",
    "    df_time_series = pd.read_csv(time_series_name, index_col=0)\n",
    "\n",
    "    df_time_series.index = pd.to_datetime(df_time_series.index)\n",
    "    df_time_series = df_time_series.rename(columns={\"band_unnamed\": \"ndvi\"})\n",
    "    df_time_series = df_time_series.drop(columns=\"feature_index\")\n",
    "    df_time_series.sort_index(inplace=True)\n",
    "    df_time_series = df_time_series.interpolate(method=\"time\")\n",
    "    df_time_series[\"date\"] = df_time_series.index\n",
    "\n",
    "    return df_time_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the functions!\n",
    "\n",
    "You can use the functions sequentially, see how they work!! Try selecting different parks.\n",
    "\n",
    "**IMPORTANT:** Processing each image takes sometime, about 5 minutes, especially for the time series!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polygon = get_polygon(gdf_paris_parks, 1679)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndvi = get_ndvi(polygon, 2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_t_ndvi = reduce_by_time(ndvi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_ndvi(reduced_t_ndvi, \"Bois de Vincennes\", 2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndvi_time_series = get_time_series(ndvi, polygon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_time_series(ndvi_time_series, \"Bois de Vincennes\", 2023)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usint the resulting objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_time_series = read_time_series(\"Bois de Vincennes\", 2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_time_series.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot images with lotly\n",
    "\n",
    "Once that we have a `.tif` image, we can use [rasterio](https://pypi.org/project/rasterio/) to open it and return a NumPy array. Take a look at the functions below, we'll use them to plot the result of the selectors in our Taipy app!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_tif(park_name, year):\n",
    "    \"\"\"\n",
    "    Reads a NDVI TIFF file and returns the image data as a numpy array.\n",
    "\n",
    "    Args:\n",
    "        park_name (str): Name of the park/location used in the filename\n",
    "        year (int or str): Year of the data used in the filename\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: 2D array containing NDVI values from the TIFF file\n",
    "    \"\"\"\n",
    "    tif_image = f\"{park_name} - {year}.tif\"\n",
    "\n",
    "    with rasterio.open(tif_image) as src:\n",
    "        ndvi_image = src.read(1)  # NDVI is one band\n",
    "\n",
    "    return ndvi_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ndvi(np_image):\n",
    "    \"\"\"\n",
    "    Create an NDVI image from a NumPy Array.\n",
    "    Args:\n",
    "        np_image: np.ndarray: A NumPy array with median season values\n",
    "            for each pixel.\n",
    "    Returns:\n",
    "        Plotly imshow figure\n",
    "    \"\"\"\n",
    "    fig = px.imshow(\n",
    "        np_image,\n",
    "        color_continuous_scale=\"RdYlGn\",\n",
    "        range_color=(-1, 1),\n",
    "        labels={\"color\": \"NDVI\"},\n",
    "    )\n",
    "    fig.update_traces(\n",
    "        hovertemplate=\"NDVI: %{z}<extra></extra>\",  # `%{z}` is the value, `<extra></extra>` removes secondary hover info\n",
    "    )\n",
    "    fig.update_layout(title=\"NDVI Map\", coloraxis_colorbar=dict(title=\"NDVI\"))\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_image = read_tif(\"Bois de Vincennes\", 2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ndvi(np_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_box(ndvi_array, park_name, year):\n",
    "    \"\"\"\n",
    "    Creates violin plot of the NDVI median yearly array.\n",
    "\n",
    "    Args:\n",
    "    ndvi_array : numpy.ndarray\n",
    "        Array wuth NDVI values\n",
    "    park_name : str\n",
    "        Name of the park\n",
    "    year : int or str\n",
    "        Observation year\n",
    "\n",
    "    Returns:\n",
    "    violin plot plotly figure\n",
    "    \"\"\"\n",
    "    flattened_data = ndvi_array.flatten()\n",
    "\n",
    "    fig = px.violin(\n",
    "        y=flattened_data,\n",
    "        title=f\"NDVI distribution for {park_name}, {year}\",\n",
    "        labels={\"y\": \"NDVI\"},\n",
    "        color_discrete_sequence=[\"#12b049\"],\n",
    "    )\n",
    "\n",
    "    fig.update_layout(\n",
    "        showlegend=False,\n",
    "        yaxis_title=\"NDVI Value\",\n",
    "        xaxis_title=\"\",\n",
    "        plot_bgcolor=\"rgba(240,240,240,0.8)\",\n",
    "        paper_bgcolor=\"rgba(240,240,240,0.5)\",\n",
    "        font=dict(family=\"Arial\", size=12),\n",
    "        margin=dict(l=20, r=20, t=40, b=20),\n",
    "    )\n",
    "\n",
    "    # NDVI range for scale: (-1 to 1)\n",
    "    fig.update_yaxes(range=[-1, 1])\n",
    "\n",
    "    # Add horizontal lines at important NDVI thresholds\n",
    "    fig.add_hline(y=0, line_dash=\"dot\", line_color=\"gray\")\n",
    "    fig.add_hline(y=0.5, line_dash=\"dot\", line_color=\"gray\")\n",
    "    fig.add_hline(y=-0.5, line_dash=\"dot\", line_color=\"gray\")\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_box(np_image, \"Bois de Vincennes\", 2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ndvi_timeseries(df, title):\n",
    "    \"\"\"\n",
    "    Line plot for time series DataFrame. The plot has indicator lines\n",
    "    for healthy vegetation and for non-vegetation index rates.\n",
    "\n",
    "    Args:\n",
    "        df : DataFrame\n",
    "            NDVI time series with a 'date' column.\n",
    "        title : str\n",
    "            Title for the plot.\n",
    "\n",
    "    Returns:\n",
    "        plotly.graph_objects.Figure\n",
    "            Line chart for the time series.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df[\"date\"] = pd.to_datetime(\n",
    "        df[\"date\"]\n",
    "    ).dt.date  # Convert to date format (remove time)\n",
    "\n",
    "    title = f\"NDVI Trend: {title}\"\n",
    "\n",
    "    fig = px.line(\n",
    "        df,\n",
    "        x=\"date\",\n",
    "        y=\"ndvi\",\n",
    "        title=title,\n",
    "        labels={\"ndvi\": \"NDVI Value\", \"date\": \"Date\"},\n",
    "        color_discrete_sequence=[\"#12b049\"],\n",
    "        template=\"plotly_white\",\n",
    "    )\n",
    "\n",
    "    fig.update_traces(\n",
    "        line_width=2.5,\n",
    "        hovertemplate=\"<b>Date</b>: %{x|%b %d}<br><b>NDVI</b>: %{y:.2f}\",\n",
    "        mode=\"lines\",\n",
    "    )\n",
    "\n",
    "    fig.update_layout(\n",
    "        yaxis_title=\"NDVI Value\",\n",
    "        xaxis_title=\"\",\n",
    "        yaxis_range=[-1, 1.05],\n",
    "        hovermode=\"x unified\",\n",
    "        plot_bgcolor=\"white\",\n",
    "        font=dict(family=\"Arial\"),\n",
    "        margin=dict(l=50, r=50, t=60, b=30),\n",
    "    )\n",
    "\n",
    "    # NDVI reference lines\n",
    "    for y, color, name in [\n",
    "        (0.5, \"#8BC34A\", \"Healthy\"),\n",
    "        (0, \"#FFC107\", \"Neutral\"),\n",
    "        (-0.2, \"#F44336\", \"Barren\"),\n",
    "    ]:\n",
    "        fig.add_hline(\n",
    "            y=y,\n",
    "            line_dash=\"dot\",\n",
    "            line_color=color,\n",
    "            opacity=0.5,\n",
    "            annotation_text=name,\n",
    "            annotation_position=\"right\",\n",
    "            annotation_font_size=10,\n",
    "        )\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ndvi_timeseries(df_time_series, \"Bois de Vincennes\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "taipy_book",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
